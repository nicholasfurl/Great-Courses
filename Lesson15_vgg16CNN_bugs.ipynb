{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMp3bvfVJyeCIMcMGmHgdFl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nicholasfurl/Great-Courses/blob/main/Lesson15_vgg16CNN_bugs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OCy7QsXxc7rV"
      },
      "outputs": [],
      "source": [
        "##########\n",
        "#-----vgg16 DCNN bug versus animal classification\n",
        "#This notebook trains an image classification model and makes gradual improvements, \n",
        "#debugging the model, to improve performance. GPUs are encouraged. \n",
        "#In colab, one can add a GPU by clicking the Runtime menu and selecting Change runtime type. \n",
        "#Selecting GPU as the hardware accelerator will allow for the usage of a GPU.\n",
        "#########"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Download tinyImageNet\n",
        "#200 categories, 500 images per category, images 64*64*3\n",
        "\n",
        "#unzipping creates a tiny-imagenet-200 folder in active directory with test, train and val subfolders and two *.txt files\n",
        "#Train subfolders have lots of further subfolders, eacj labveled n10*. Within each is some text files and an images folder\n",
        "#containing n*.JPEG images\n",
        "#Test subfolder has subfolder images with test_*JPEG files\n",
        "!wget http://cs231n.stanford.edu/tiny-imagenet-200.zip\n",
        "!unzip -q tiny-imagenet-200.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A2CAkx1idnXH",
        "outputId": "04c3a1ab-aea9-45b1-9051-cbfa14ed8493"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-01-03 16:30:48--  http://cs231n.stanford.edu/tiny-imagenet-200.zip\n",
            "Resolving cs231n.stanford.edu (cs231n.stanford.edu)... 171.64.68.10\n",
            "Connecting to cs231n.stanford.edu (cs231n.stanford.edu)|171.64.68.10|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 248100043 (237M) [application/zip]\n",
            "Saving to: ‘tiny-imagenet-200.zip’\n",
            "\n",
            "tiny-imagenet-200.z 100%[===================>] 236.61M  20.1MB/s    in 15s     \n",
            "\n",
            "2023-01-03 16:31:03 (16.0 MB/s) - ‘tiny-imagenet-200.zip’ saved [248100043/248100043]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras=='2.8.0'\n",
        "#from PIL import Image    #I knpow from previous lessons that this doesn't work\n",
        "import keras.utils as image #This is the one that works\n",
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHA-A_0NnLAI",
        "outputId": "048db074-8fbd-4f70-9299-1b410d087499"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting keras==2.8.0\n",
            "  Downloading keras-2.8.0-py2.py3-none-any.whl (1.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 4.2 MB/s \n",
            "\u001b[?25hInstalling collected packages: keras\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.9.0\n",
            "    Uninstalling keras-2.9.0:\n",
            "      Successfully uninstalled keras-2.9.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.9.2 requires keras<2.10.0,>=2.9.0rc0, but you have keras 2.8.0 which is incompatible.\u001b[0m\n",
            "Successfully installed keras-2.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#specify folder names  (for training set?)\n",
        "cats_0 = ['n01443537','n01629819','n01641577','n01644900','n01698640','n01742172',\n",
        "          'n01855672','n01882714','n02002724','n02056570','n02058221','n02074367',\n",
        "          'n02085620','n02094433','n02099601','n02099712','n02106662','n02113799',\n",
        "          'n02123045','n02123394','n02124075','n02125311','n02129165','n02132136',\n",
        "          'n02364673','n02395406','n02403003','n02410509','n02415577','n02423022',\n",
        "          'n02437312','n02480495','n02481823','n02486410','n02504458','n02509815']\n",
        "cats_1 = ['n01770393','n01774384','n01774750','n01784675','n02165456','n02190166',\n",
        "          'n02206856','n02226429','n02231487','n02233338','n02236044','n02268443',\n",
        "          'n02279972','n02281406']"
      ],
      "metadata": {
        "id": "8aBV4q8lfACD"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#function def to read files and return training and test sets\n",
        "\n",
        "#the cats argument will be one of the \n",
        "def read_cats(cats, lab, train_size, test_size):\n",
        "\n",
        "  #initialise stuff for loop\n",
        "  vecs = []\n",
        "  labs = []\n",
        "\n",
        "  num_images_per_folder = 500 #a bit more explanatory and robust than it was\n",
        "\n",
        "  #loop through each folder name (a subcategory of animals or bugs) and then through the images in that folder\n",
        "  for c in cats:  #folder names from argument\n",
        "    for i in range(num_images_per_folder): #num images per folder`\n",
        "\n",
        "    #load the image and convert it to an array\n",
        "      img = image.load_img(\"tiny-imagenet-200/train/\"+c+\"/images/\"+c+\"_\"+str(i)+\".JPEG\")\n",
        "      img_arr = image.img_to_array(img)\n",
        "      \n",
        "\n",
        "      #vectorise then reshape? This appears to vectorise it and then just put it back as it was again! Why?\n",
        "      #print(c, i, img_arr.shape) \n",
        "      img_arr = img_arr.flatten() #this is numpy not image\n",
        "      #print(c, i, img_arr.shape)\n",
        "      img_arr = img_arr.reshape(64,64,3)\n",
        "      #print(c, i, img_arr.shape)\n",
        "\n",
        "      \n",
        "      vecs += [img_arr] #Accumulates 2D arrays? Or should it be vectorised?\n",
        "      labs += [lab]   #But this will just be [] every time? Something's not right here ....\n",
        "\n",
        "  vecs = np.asarray(vecs) #convert to array\n",
        "  return(train_test_split(vecs,labs, train_size=train_size,test_size=test_size))"
      ],
      "metadata": {
        "id": "Mla2Xy-ChicZ"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X0_train, X0_test, y0_train, y0_test = read_cats(cats_0, 0, .1, .2) #So hand it the animals (category 0), make its label 0, and train size will be .1q and test_size will be .2. Why pass these last two just to return them again? No idea, seems like unncessary complexity\n",
        "X1_train, X1_test, y1_train, y1_test = read_cats(cats_1, 1, .1, .2)\n",
        "#print(X0_train.shape) #1800*64*64*3 is what I want? According to the lecture, yes.\n",
        "#print(y0_train)  #1800 0's is what I want? Yes, you gave lab as an argument so one run will be handed 0o and the other 1.\n",
        "\n",
        "#Put all training examples together and all test examples together\n",
        "X_train = np.concatenate((X0_train, X1_train))\n",
        "X_test = np.concatenate((X0_test, X1_test))\n",
        "y_train = np.concatenate((y0_train, y1_train))\n",
        "y_test = np.concatenate((y0_test, y1_test))"
      ],
      "metadata": {
        "id": "QbkJTT-0pu9g"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Built vgg model!"
      ],
      "metadata": {
        "id": "4Kq3Xm0TwdV7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}